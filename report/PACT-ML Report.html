<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Felix Kube">
<meta name="dcterms.date" content="2025-05-18">
<meta name="keywords" content="Machine Learning, Natural Language Processing, United Nations Peacekeeping, BERT, roBERTa">

<title>PACT-ML: Coding United Nation Peacekeeping ACtivities from reports to the Secretary-General</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="PACT-ML Report_files/libs/clipboard/clipboard.min.js"></script>
<script src="PACT-ML Report_files/libs/quarto-html/quarto.js"></script>
<script src="PACT-ML Report_files/libs/quarto-html/popper.min.js"></script>
<script src="PACT-ML Report_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="PACT-ML Report_files/libs/quarto-html/anchor.min.js"></script>
<link href="PACT-ML Report_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="PACT-ML Report_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="PACT-ML Report_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="PACT-ML Report_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="PACT-ML Report_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="PACT-ML Report_files/libs/kePrint-0.0.1/kePrint.js"></script>

<link href="PACT-ML Report_files/libs/lightable-0.0.1/lightable.css" rel="stylesheet">


  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-intro" id="toc-sec-intro" class="nav-link active" data-scroll-target="#sec-intro"><span class="header-section-number">1</span> Introduction</a></li>
  <li><a href="#sec-data" id="toc-sec-data" class="nav-link" data-scroll-target="#sec-data"><span class="header-section-number">2</span> Data</a>
  <ul class="collapse">
  <li><a href="#validity-checks" id="toc-validity-checks" class="nav-link" data-scroll-target="#validity-checks"><span class="header-section-number">2.1</span> Validity checks</a></li>
  <li><a href="#uncertainty-quantification" id="toc-uncertainty-quantification" class="nav-link" data-scroll-target="#uncertainty-quantification"><span class="header-section-number">2.2</span> Uncertainty quantification</a></li>
  </ul></li>
  <li><a href="#sec-eda" id="toc-sec-eda" class="nav-link" data-scroll-target="#sec-eda"><span class="header-section-number">3</span> Exploratory Data Analysis</a>
  <ul class="collapse">
  <li><a href="#text-corpus-analysis" id="toc-text-corpus-analysis" class="nav-link" data-scroll-target="#text-corpus-analysis"><span class="header-section-number">3.1</span> Text Corpus Analysis</a></li>
  <li><a href="#category-specific-analysis" id="toc-category-specific-analysis" class="nav-link" data-scroll-target="#category-specific-analysis"><span class="header-section-number">3.2</span> Category-Specific Analysis</a></li>
  <li><a href="#semantic-analysis" id="toc-semantic-analysis" class="nav-link" data-scroll-target="#semantic-analysis"><span class="header-section-number">3.3</span> Semantic Analysis</a></li>
  </ul></li>
  <li><a href="#sec-meth" id="toc-sec-meth" class="nav-link" data-scroll-target="#sec-meth"><span class="header-section-number">4</span> Modeling approach</a>
  <ul class="collapse">
  <li><a href="#term-frequencyinverse-document-frequency-tf-idf" id="toc-term-frequencyinverse-document-frequency-tf-idf" class="nav-link" data-scroll-target="#term-frequencyinverse-document-frequency-tf-idf"><span class="header-section-number">4.1</span> Term Frequency–Inverse Document Frequency (TF-IDF)</a></li>
  <li><a href="#bidirectional-encoder-representations-from-transformers-bert" id="toc-bidirectional-encoder-representations-from-transformers-bert" class="nav-link" data-scroll-target="#bidirectional-encoder-representations-from-transformers-bert"><span class="header-section-number">4.2</span> Bidirectional Encoder Representations from Transformers (BERT)</a></li>
  <li><a href="#cross-validation-strategy" id="toc-cross-validation-strategy" class="nav-link" data-scroll-target="#cross-validation-strategy"><span class="header-section-number">4.3</span> Cross-Validation strategy</a></li>
  </ul></li>
  <li><a href="#sec-results" id="toc-sec-results" class="nav-link" data-scroll-target="#sec-results"><span class="header-section-number">5</span> Results</a>
  <ul class="collapse">
  <li><a href="#parameter-optimization" id="toc-parameter-optimization" class="nav-link" data-scroll-target="#parameter-optimization"><span class="header-section-number">5.1</span> Parameter optimization</a></li>
  </ul></li>
  <li><a href="#sec-conc" id="toc-sec-conc" class="nav-link" data-scroll-target="#sec-conc"><span class="header-section-number">6</span> Conclusion</a></li>
  <li><a href="#annex" id="toc-annex" class="nav-link" data-scroll-target="#annex"><span class="header-section-number">7</span> Annex</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">PACT-ML: Coding United Nation Peacekeeping ACtivities from reports to the Secretary-General</h1>
<p class="subtitle lead">Using Bag-of-Words approaches and BERT models</p>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Felix Kube </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Hertie School
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">May 18, 2025</p>
    </div>
  </div>
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="block-title">Abstract</div>
    <p>The Peacekeeping Activity Dataset (PACT) is the first of its kind data collection to shine light on what peacekeepers actually implement while deployed. In the past, many projects have looked towards mandates to study how specific tasks and mission success are related. PACT used report data from the mission heads to the Secretary-General of the UN to code up to 39 categories of task implementation on six different engagement levels. This project, PACT-ML, aims to extend the data collections of PACT 1.0 (<span class="citation" data-cites="Blair2022">Blair et al. (<a href="#ref-Blair2022" role="doc-biblioref">2022</a>)</span>) and PACT 2.0 (<span class="citation" data-cites="PACT2">Otto (<a href="#ref-PACT2" role="doc-biblioref">2024</a>)</span>, <span class="citation" data-cites="Otto2024">Otto et al. (<a href="#ref-Otto2024" role="doc-biblioref">2024</a>)</span>) by using selected reports of PACT 2.0 to examine the application of Machine Learning / Natural Language Processing techniques to automatically code this sort of data from the reports.</p>
  </div>
</div>

<div>
  <div class="keywords">
    <div class="block-title">Keywords</div>
    <p>Machine Learning, Natural Language Processing, United Nations Peacekeeping, BERT, roBERTa</p>
  </div>
</div>

</header>


<section id="sec-intro" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="sec-intro"><span class="header-section-number">1</span> Introduction</h2>
<p>In recent years, United Nations peacekeeping operations (UNPKOs) have faced growing political resistance and resource constraints, resulting in a stagnation of new mission mandates and increasing difficulty in sustaining existing ones. At the same time, efforts to systematically monitor and evaluate peacekeeping effectiveness—particularly through structured data collection—have become more difficult to maintain. This study explores the feasibility of using natural language processing (NLP) and machine learning methods to automatically code newly written peacekeeping mission reports. The motivation stems from the recognition that manual coding efforts, such as those employed in the PACT project, are resource-intensive and unlikely to be extended to cover post-2018 mission data. As such, automated coding presents a scalable alternative to support continued research and institutional monitoring.</p>
<p>The empirical foundation of this effort is the PACT 2.0 dataset (<span class="citation" data-cites="PACT2">Otto (<a href="#ref-PACT2" role="doc-biblioref">2024</a>)</span>), which codes the activities of peacekeeping missions based on United Nations Secretary-General (UNSG) progress reports. PACT 2.0 builds on the original Peacekeeping Activity Dataset (PACT 1.0, yet unreleased) and extends its geographic scope beyond Africa to include 23 missions across Europe, the Americas, and Asia, all mandated after 1988 in civil war contexts (<span class="citation" data-cites="PACT2CB">Otto and Honda (<a href="#ref-PACT2CB" role="doc-biblioref">2024</a>)</span>). The dataset captures operational behavior at the paragraph level—tracking specific actions undertaken by peacekeepers, the nature of their engagement, and whether these activities involved international partners. Reports are coded in fine detail, producing a rich training corpus for supervised machine learning approaches. The goal of this work is to assess whether models trained on PACT-coded data can automatically identify similar activities in new, uncoded reports.</p>
<p>This initiative also draws inspiration from related efforts such as the PEMA (Peacekeeping Mandates) dataset (<span class="citation" data-cites="Salvatore2022">Salvatore et al. (<a href="#ref-Salvatore2022" role="doc-biblioref">2022</a>)</span>), which systematically codes peacekeeping tasks as defined in Security Council resolutions. PEMA distinguishes among various modalities (e.g., monitoring, assisting, securing) and levels of directive authority (requested vs.&nbsp;encouraged), offering insights into how mandates evolve and guide operational priorities. While PEMA focuses on mandated intent, PACT focuses on reported implementation, offering a valuable complement for understanding peacekeeping effectiveness on the ground. Automating this kind of report-level analysis could help bridge the gap between what peacekeepers are tasked to do and what they actually report doing—at scale and in near real time.</p>
<p>In sum, this study tests whether combining high-quality annotated data from the PACT project with modern NLP techniques can offer a scalable solution to peacekeeping data collection, thereby enabling continuous monitoring of peacekeeping behavior even in the absence of new manual coding efforts.</p>
</section>
<section id="sec-data" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="sec-data"><span class="header-section-number">2</span> Data</h2>
<ul>
<li>Describe PACT data, describe report formats, reference the PACT/PEMA codebooks with same coding categories for all reports since 1989</li>
</ul>
<p>This is a sentence.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>Some old reports (e.g.&nbsp;ONUCA) were left out due to issues in parsing, because the official UN documents are just a bad scan of typewritten reports. UNMIBH and UNTAET reports were left out due to their two-column layout. We also decided for the exclusion of cross-country reports (missions active in more than one country) due to issues with the systematic difference in language to describe activities and the adjacent codings, which are sometimes at the country level and sometimes at the report level. For identifying the reports to parse and use for the model, we used ‘PyMuPDF’ and selected based on some characteristics from the file, like first page margins. The reports were then clustered using kNN, and the second cluster included the report types that could be parsed. There were 133 reports identified, which was deemed sufficient for the scope of this term paper. If we assume that the content of the reports and the features of the layout used for clustering do not coincide, the subsetting should not interfere with our results systematically. In summary, the data mostly corresponds to post-2000 UN reports included in the PACT 2.0 data set, which coincides with the third and fourth generations of UN Peacekeeping Missions.</p>
<section id="validity-checks" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="validity-checks"><span class="header-section-number">2.1</span> Validity checks</h3>
<p>To be able to use our models on the data, we need to identify which paragraph text belongs to the specific coding in the PACT 2.0 data set. We take the paragraph number, from which the manual coders at the University of Uppsala made their judgement, as ground truth. We do this because it is highly unlikely that mistakes happened, as each paragraph as per the UN reporting scheme carries its paragraph number at the beginning, and coders had to mark the relevant sentences within the PDFs before adding them to the database.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>The reports were then parsed. Since the Annexes were not as expected in a separate file, but included in the main report, the numbering at times was not consecutive, but started again at ‘1.’ in the middle of the parsed paragraphs. To sucessfully eliminate the paragraphs that were extracted from the Annexes, the paragraph’s number at the beginning of each paragraph needed to increase strictly monotonically. Reports failed the parsing pipeline and were not added to the training data if the extracted paragraphs were 10% more or less than the expected paragraphs according to the PACT data. This ensures good data quality for the parsed reports.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<div id="fig-parsing" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-parsing-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-parsing" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-annex" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-annex-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="_static/Annex_parsing.png" class="img-fluid figure-img" data-ref-parent="fig-parsing">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-annex-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Removing annex paragraphs during parsing
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-parsing" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-fails" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-fails-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="_static/Parsing_fails.png" class="img-fluid figure-img" data-ref-parent="fig-parsing">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-fails-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Parsing fails due to 10% threshold
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-parsing-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Examples of the parsing pipeline in action.
</figcaption>
</figure>
</div>
<p>Table 2 shows the number of reports per UNPKO in PACT 2.0, as well as shares of the reports that made it through pre-selection and parsing. As can be seen, the PDF-formats that the parsing pipeline was able to process is heavily skewed towards a few missions. This is not surprising, as some missions took place only in the 1990s, while the included missions are mostly of the newer peacekeeping generations.</p>
<div class="cell" data-caption="Included reports in PACT 2.0, after pre-selection and after parsing (also in %).">
<div id="tbl-included" class="cell quarto-float anchored" data-caption="Included reports in PACT 2.0, after pre-selection and after parsing (also in %).">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-included-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Included reports in PACT 2.0, after pre-selection and after parsing (also in %).
</figcaption>
<div aria-describedby="tbl-included-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div>
<div class="table-responsive">
<table class="table table-striped table-hover table-condensed do-not-create-environment cell table-sm small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th style="text-align: center;" data-quarto-table-cell-role="th">PKO</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">Total Reports</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">After pre-selection</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">After parsing</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">Coverage (Selection)</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">Coverage (Parsing)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">MINUGUA</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA%</td>
<td style="text-align: center;">NA%</td>
</tr>
<tr class="even">
<td style="text-align: center;">MINUJUSTH</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">NA%</td>
<td style="text-align: center;">100.0%</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MINUSTAH</td>
<td style="text-align: center;">38</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">30</td>
<td style="text-align: center;">NA%</td>
<td style="text-align: center;">78.9%</td>
</tr>
<tr class="even">
<td style="text-align: center;">MIPONHU</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA%</td>
<td style="text-align: center;">NA%</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MIPONUH</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA%</td>
<td style="text-align: center;">NA%</td>
</tr>
<tr class="even">
<td style="text-align: center;">ONUCA</td>
<td style="text-align: center;">27</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA%</td>
<td style="text-align: center;">NA%</td>
</tr>
<tr class="odd">
<td style="text-align: center;">ONUSAL</td>
<td style="text-align: center;">21</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA%</td>
<td style="text-align: center;">NA%</td>
</tr>
<tr class="even">
<td style="text-align: center;">UNCRO</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA%</td>
<td style="text-align: center;">NA%</td>
</tr>
<tr class="odd">
<td style="text-align: center;">UNMIBH</td>
<td style="text-align: center;">23</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA%</td>
<td style="text-align: center;">NA%</td>
</tr>
<tr class="even">
<td style="text-align: center;">UNMIH</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA%</td>
<td style="text-align: center;">NA%</td>
</tr>
<tr class="odd">
<td style="text-align: center;">UNMIK</td>
<td style="text-align: center;">74</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">38</td>
<td style="text-align: center;">NA%</td>
<td style="text-align: center;">51.4%</td>
</tr>
<tr class="even">
<td style="text-align: center;">UNMISET</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">NA%</td>
<td style="text-align: center;">40.0%</td>
</tr>
<tr class="odd">
<td style="text-align: center;">UNMISH</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA%</td>
<td style="text-align: center;">NA%</td>
</tr>
<tr class="even">
<td style="text-align: center;">UNMIT</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">NA%</td>
<td style="text-align: center;">100.0%</td>
</tr>
<tr class="odd">
<td style="text-align: center;">UNMOP</td>
<td style="text-align: center;">56</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA%</td>
<td style="text-align: center;">NA%</td>
</tr>
<tr class="even">
<td style="text-align: center;">UNMOT</td>
<td style="text-align: center;">23</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA%</td>
<td style="text-align: center;">NA%</td>
</tr>
<tr class="odd">
<td style="text-align: center;">UNOMIG</td>
<td style="text-align: center;">63</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">NA%</td>
<td style="text-align: center;">11.1%</td>
</tr>
<tr class="even">
<td style="text-align: center;">UNPREDEP</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA%</td>
<td style="text-align: center;">NA%</td>
</tr>
<tr class="odd">
<td style="text-align: center;">UNPROFOR</td>
<td style="text-align: center;">38</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA%</td>
<td style="text-align: center;">NA%</td>
</tr>
<tr class="even">
<td style="text-align: center;">UNPSG</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA%</td>
<td style="text-align: center;">NA%</td>
</tr>
<tr class="odd">
<td style="text-align: center;">UNSMIH</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA%</td>
<td style="text-align: center;">NA%</td>
</tr>
<tr class="even">
<td style="text-align: center;">UNTAC</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA%</td>
<td style="text-align: center;">NA%</td>
</tr>
<tr class="odd">
<td style="text-align: center;">UNTAES</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA%</td>
<td style="text-align: center;">NA%</td>
</tr>
<tr class="even">
<td style="text-align: center;">UNTAET</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA%</td>
<td style="text-align: center;">NA%</td>
</tr>
<tr class="odd">
<td style="text-align: center;">UNTMIH</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA%</td>
<td style="text-align: center;">NA%</td>
</tr>
</tbody>
</table>
</div>


</div>
</div>
</div>
</figure>
</div>
</div>
<p>Interestingly, we can see that some reports included after pre-selection do not appear in the PACT 2.0 dataset, meaning that there were no peackeeping activities carried out at the time of the report. This concerns three reports in UNIKOM, as well as one report in UNMIT. Most reports were filtered out for UNOMIG, which is again not surprising, as the mission lasted from 1993 until 2009, meaning that most early reports were in the typewritten format and therefore disgarded. For our models, this means that results are generalizable only to a certain extent, which will be discussed in <a href="#sec-conc" class="quarto-xref">Section&nbsp;6</a>.</p>
<p>In total, we were able to extract 6029 paragraphs, from which 1819 were matched to codings in PACT 2.0. There were multi-label paragraphs (paragraphs that reported more than one activity) in 256 cases. For 29 paragraphs out of the included reports, parsing failed on the paragraph level.</p>
</section>
<section id="uncertainty-quantification" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="uncertainty-quantification"><span class="header-section-number">2.2</span> Uncertainty quantification</h3>
<p>Unlike the paragraph number, which we take as ground truth, the coding itself can not be considered to be ground truth. <span class="citation" data-cites="Bachl2024">Bachl and Scharkow (<a href="#ref-Bachl2024" role="doc-biblioref">forthcoming</a>)</span> discuss the importance of accurate and consistent human classification, particularly in the context of supervised computational text analysis (CTA) methods. This human input is analogous to the role of human coders in traditional content analysis, where intercoder reliability is a key concern. Content analysis is particularly vulnerable to measurement error because it depends on the “consensual reading” (<span class="citation" data-cites="Krippendorff2018">Krippendorff (<a href="#ref-Krippendorff2018" role="doc-biblioref">2018</a>)</span>, p.&nbsp;212) of messages that are semantically or visually ambiguous, interpreted by different coders or at different times.</p>
<p>Errors in this input (akin to having training data that is not “ground truth”, or low intercoder reliability for this case) can increase error rates:</p>
<ol type="1">
<li><p>Supervised CTA relies on human judgment: Supervised approaches to CTA require human intervention. Researchers must provide either pre-defined classification rules or example texts that have been classified by humans. These classified examples or rules serve as the training material from which computational algorithms learn to classify large amounts of text.</p></li>
<li><p>Errors bias the analysis results: These errors can, in turn, bias the results of an analysis based on the classification. This means if the human-classified training data contains errors or inconsistencies (i.e., is not “ground truth”), the model trained on this data will learn these errors and inconsistencies, leading to biased or inaccurate classifications on new data and increasing the overall error rate of the CTA. Generally, the error rate grows exponentially if a bias is introduced at the first stage.</p></li>
</ol>
<p><span class="citation" data-cites="Bachl2017">Bachl and Scharkow (<a href="#ref-Bachl2017" role="doc-biblioref">2017</a>)</span> introduce a method to counter this using matrix back-calculation. Sadly, the intercoder reliability checks for the process of coding PACT 2.0 were not available to me, which is why the uncertainty estimates and error rates are not quantified further based on the reliability of the training sources. Without multiple codings for the same paragraph, and the decision that was made for the final data set, potential systematic bias can not be worked out. In general, the error rates reported in <a href="#sec-results" class="quarto-xref">Section&nbsp;5</a> are therefore likely to underestimate the true error rates of classification.</p>
</section>
</section>
<section id="sec-eda" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="sec-eda"><span class="header-section-number">3</span> Exploratory Data Analysis</h2>
<section id="text-corpus-analysis" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="text-corpus-analysis"><span class="header-section-number">3.1</span> Text Corpus Analysis</h3>
<p><a href="#fig-text-lengths" class="quarto-xref">Figure&nbsp;2</a> shows that paragraphs included in the models (i.e.&nbsp;that included peacekeeping activities) did only differ sligthly from all parsed paragraphs (mean 123 vs.&nbsp;117 tokens; median 112 vs.&nbsp;102 tokens), indicating that peacekeeping-relevant information is not strongly associated with paragraph length. This suggests that semantic content—rather than verbosity—drives relevance, and supports the feasibility of using NLP models that rely on textual meaning rather than surface-level features. However, it is important to note that parsing is more likely to fail for longer paragraphs, as they often include numbered lists or bullet points. Further, if a line starts with a number (e.g.&nbsp;“The second unit went on patrol and encountered with the local authorities of district <em>linebreak</em> <strong>17.</strong>”), the parsing shortened the paragraph, as everything after the number 17 would be recognized as a new paragraph, and removed during the check for consecutive numbering.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<div id="fig-text-lengths" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-text-lengths-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-text-lengths" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-text-lengths-1" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-text-lengths-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="PACT-ML-Report_files/figure-html/fig-text-lengths-1.png" class="img-fluid figure-img" data-ref-parent="fig-text-lengths" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-text-lengths-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Included paragraphs
</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-text-lengths" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-text-lengths-2" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-text-lengths-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="PACT-ML-Report_files/figure-html/fig-text-lengths-2.png" class="img-fluid figure-img" data-ref-parent="fig-text-lengths" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-text-lengths-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) All parsed paragraphs
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-text-lengths-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Distribution of Paragraph Lengths
</figcaption>
</figure>
</div>
<p>Looking more specific at the vocabulary, we identified the use of 7383 unique words (including stop-words). <a href="#tbl-voc" class="quarto-xref">Table&nbsp;2</a> shows the relation to the total number of words. The rather low value of for type-token ratio of 0.063 indicates repetition, formulaic writing, or specialized language, which we expect for the normed UN reporting (<span class="citation" data-cites="UN2019"><em>Integrated reporting from peacekeeping operations to UNHQ</em> (<a href="#ref-UN2019" role="doc-biblioref">2019</a>)</span>). Therefore, language seems to be rather standardized across reports. For our language model to be able to code the paragraphs into peacekeeping activities well, we need to look at differentiated language use across categories.</p>
<div id="tbl-voc" class="quarto-float anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-voc-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: Vocabulary size and Type-token ratio.
</figcaption>
<div aria-describedby="tbl-voc-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<thead>
<tr class="header">
<th style="text-align: right;">Total words</th>
<th style="text-align: right;">Unique words</th>
<th style="text-align: right;">Type-token ratio</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">117704</td>
<td style="text-align: right;">7383</td>
<td style="text-align: right;">0.0627251</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>To analyze the text corpus further, we look at Zipf’s law of natural language. <span class="citation" data-cites="Zipf1949">Zipf (<a href="#ref-Zipf1949" role="doc-biblioref">1949</a>)</span> says:</p>
<div class="blockquote">
<p>If one ranks all the words occurring in a large corpus of natural language texts by their frequency of occurrence, the frequency of any word is inversely proportional to its rank.</p>
</div>
<p>The Zipf’s Law plot of the corpus shows a clear power-law distribution of word frequencies, confirming that the text follows the statistical patterns typical of natural language. A small number of words are extremely frequent, while the majority are rare—consistent with Zipfian behavior. However, this observation stands in contrast to the relatively low type-token ratio observed in the data, which suggests a more repetitive, possibly technical or formulaic language with limited lexical diversity. This apparent contradiction can be explained by the specialized nature of the corpus: although the overall distribution of word frequencies follows natural language norms, the specific context (i.e.&nbsp;peacekeeping reports) likely relies on a constrained vocabulary and frequent reuse of mission-specific terminology. This supports the use of contextual models (e.g., transformer-based embeddings) over token frequency-based approaches like TF-IDF, which may not adequately capture semantic distinctions in this type of structured and domain-specific text.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-zipf" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-zipf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="PACT-ML-Report_files/figure-html/fig-zipf-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-zipf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Zipf’s Law Plot: Word Frequency vs Rank (Log-Log Scale)
</figcaption>
</figure>
</div>
</div>
</div>
<section id="n-gram-analysis" class="level4" data-number="3.1.1">
<h4 data-number="3.1.1" class="anchored" data-anchor-id="n-gram-analysis"><span class="header-section-number">3.1.1</span> N-Gram Analysis</h4>
<p><a href="#fig-ngrams" class="quarto-xref">Figure&nbsp;4</a> displays the most frequent trigrams and bigrams in the text corpus of peacekeeping mission reports included in the models, and offer insight into the dominant themes and institutional actors mentioned. The top trigrams such as:</p>
<ul>
<li>“haitian national police”</li>
<li>“port au prince”</li>
<li>“gender based violence”</li>
<li>“internally displaced persons”</li>
<li>“united nations country”</li>
</ul>
<p>and corresponding bigrams (not shown, but often subsumed in these trigrams), suggest a strong institutional framing. This language reflects the frequent reference to national institutions (e.g., “haitian national police”), geographic anchors (e.g., “port au prince”), and core thematic concerns of peacekeeping operations, such as gender-based violence, displacement, and human rights violations.</p>
<p>With the references to national authorities, categories like ‘PoliceReform’ can be identified well, since the mentioning of the name for national authorities can link activities to specific common terms used to name these autorities. On the other hand, geographical anchors may bias the results. The importance of these features in combination with differentiated activity implementation across missions can lead the model to learn that the activity was carried out because of the location, not because of activity-specific language. This has potential implications for model generalization. We will discuss feature importance in <a href="#sec-results" class="quarto-xref">Section&nbsp;5</a>.</p>
<div id="fig-ngrams" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ngrams-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-ngrams" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-ngrams-1" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-ngrams-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="PACT-ML-Report_files/figure-html/fig-ngrams-1.png" class="img-fluid figure-img" data-ref-parent="fig-ngrams" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-ngrams-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Top 20 Most Frequent Bigrams
</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-ngrams" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-ngrams-2" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-ngrams-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="PACT-ML-Report_files/figure-html/fig-ngrams-2.png" class="img-fluid figure-img" data-ref-parent="fig-ngrams" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-ngrams-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Top 15 Most Frequent Trigrams
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ngrams-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: N-Gram Frequencies
</figcaption>
</figure>
</div>
<p>Below are the most relevant bigrams (cutoff for frequency higher than 50, <a href="#fig-ngram-network-1" class="quarto-xref">Figure&nbsp;5 (a)</a>) and trigrams (frequencies higher than 25, <a href="#fig-ngram-network-2" class="quarto-xref">Figure&nbsp;5 (b)</a>). These network graphs embed the most frequent bi- and trigrams into a larger context of appearance.</p>
<div id="fig-ngram-network" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ngram-network-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-ngram-network" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-ngram-network-1" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-ngram-network-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="PACT-ML-Report_files/figure-html/fig-ngram-network-1.png" class="img-fluid figure-img" data-ref-parent="fig-ngram-network" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-ngram-network-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Bigrams (n &gt; 50)
</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-ngram-network" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-ngram-network-2" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-ngram-network-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="PACT-ML-Report_files/figure-html/fig-ngram-network-2.png" class="img-fluid figure-img" data-ref-parent="fig-ngram-network" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-ngram-network-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Trigrams (n &gt; 25)
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ngram-network-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: N-Gram Networks
</figcaption>
</figure>
</div>
</section>
</section>
<section id="category-specific-analysis" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="category-specific-analysis"><span class="header-section-number">3.2</span> Category-Specific Analysis</h3>
<div class="cell" data-fig-caption="Lexical Diversity by Category">
<div class="cell-output-display">
<div id="fig-lex-diversity" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-lex-diversity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="PACT-ML-Report_files/figure-html/fig-lex-diversity-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-lex-diversity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Type-Token Ratio (higher values indicate greater diversity)
</figcaption>
</figure>
</div>
</div>
</div>
<p>The differences in Type-Token Ratio (TTR) across categories have important implications for our modeling approaches. For Bag-of-Words (BoW) models, high TTR categories like ‘RefugeeAssistance’ may lead to sparser feature representations due to their richer vocabulary, which can affect model performance if not enough training data is available. Conversely, low TTR categories like ‘PoliceReform’ may produce denser, more repetitive word distributions, potentially making them easier to model with BoW but also more susceptible to overfitting on frequent terms. For BERT models, which capture contextual semantics, high lexical diversity can enhance learning if the model is exposed to varied contexts, but it may also challenge generalization if vocabulary usage is highly domain-specific.</p>
<div id="fig-co-occurence" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-co-occurence-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-co-occurence" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-co-occurence-1" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-co-occurence-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="PACT-ML-Report_files/figure-html/fig-co-occurence-1.png" class="img-fluid figure-img" data-ref-parent="fig-co-occurence" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-co-occurence-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) PACT 2.0
</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-co-occurence" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-co-occurence-2" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-co-occurence-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="PACT-ML-Report_files/figure-html/fig-co-occurence-2.png" class="img-fluid figure-img" data-ref-parent="fig-co-occurence" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-co-occurence-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Included Paragraphs
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-co-occurence-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: Category Co-Occurence for Target Categories
</figcaption>
</figure>
</div>
<p>The co-occurence matrices in <a href="#fig-co-occurence" class="quarto-xref">Figure&nbsp;7</a> indicate very similar co-occurences in the subset of data compared to the full PACT 2.0, with slightly higher co-occurence of the labels ‘PoliceReform’ with ‘LegalReform’ and ‘CivilSocietyAssistance’. To our advantage, the co-occurence of textually related categories of ‘PoliceReform’ and ‘Operations’, which both may use police or military language, is smaller in our subset.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-label-distr" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-label-distr-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="PACT-ML-Report_files/figure-html/fig-label-distr-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-label-distr-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: Comparison of Label Distributions
</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#fig-label-distr" class="quarto-xref">Figure&nbsp;8</a> shows that the overall label distributions stays comparable between the full PACT 2.0 data set and the subset parsed for analysis. Notably, ‘CivilSocietyAssistance’ is carried out heavier in the selected mission reports, while there was less use of force. This finding makes sense, as the use of force is only mandated for very specific third and fourth generation UNPKOs, also referred to as “robust” peacekeeping missions. These missions were mostly deployed in armed conflicts in Africa. Since the data of PACT 1.0, which covers Africa, was not available, the reported activities in our subset rely heavily on the UNOMIG mission (<a href="#fig-label-per-mission" class="quarto-xref">Figure&nbsp;9</a>). This potentially leads to results that rely on mission-specific wording or geographic anchors in our models.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-label-per-mission" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-label-per-mission-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="PACT-ML-Report_files/figure-html/fig-label-per-mission-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-label-per-mission-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9: Proportional Label Distribution by Mission for Included Paragraphs
</figcaption>
</figure>
</div>
</div>
</div>
<p>For the other missions, most labels are present in varying proportions. Especially for the feature importance of geographical anchors, the multiplicity of missions per label should lead to better results and less importance of these geographical tokens, as they differ for different missions. Expanding the included paragraphs beyond the scope possible here should therefore lead to even less dependance on these features.</p>
<p>Looking at the word clouds for the complete text data by categories (<a href="#fig-category-analysis-1" class="quarto-xref">Figure&nbsp;10 (a)</a>), we can see that some words are heavily replicated in different categories. The term “police” on its own for example is present in three different categories as a central term. These duplications point to the semantic structure and usage of the term as an important distinction for extracting the correct labels from the paragraph data.</p>
<p><a href="#fig-category-analysis-2" class="quarto-xref">Figure&nbsp;10 (b)</a> shows the distinctive terms by their TF-IDF score, which reflects the importance of each term within a given category relative to its distribution across the entire corpus. TF-IDF, or Term Frequency–Inverse Document Frequency, is computed using the following formula:</p>
<p><span class="math display">\[
\text{TF-IDF}(t, d, D) = \text{TF}(t, d) \times \text{IDF}(t, D) = \frac{f_{t,d}}{\sum_{t' \in d} f_{t',d}} \times \log\left(\frac{N}{1 + \left| \{ d' \in D : t \in d' \} \right|}\right)
\]</span></p>
<p>This version uses log-scaled inverse document frequency with term frequency normalized by document length, which is a common implementation (e.g.&nbsp;in ‘scikit-learn’).</p>
<p>The distinctive terms are guaranteed to be different in a multi-label setup, but missing key terminology like “police” may still lead to a higher missclassification rate, especially regarding false positives.</p>
<p>For both approaches, traditional word counts and TF-IDF scores, geographical anchors like “kosovo” or “georgian” appear in the features, which is not surprising for the imbalanced label distributions within and across different UNPKOs. UNMIK, which was active in Kosovo, implemented the highest share of ‘CivilSocietyAssistance’. UNOMIG on the other hand, which was active in Georgia, had the relatively highest codings for ‘Operations’.</p>
<div id="fig-category-analysis" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-category-analysis-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-category-analysis" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-category-analysis-1" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-category-analysis-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="PACT-ML-Report_files/figure-html/fig-category-analysis-1.png" class="img-fluid figure-img" data-ref-parent="fig-category-analysis" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-category-analysis-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Word Clouds by Category
</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-category-analysis" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-category-analysis-2" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-category-analysis-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="PACT-ML-Report_files/figure-html/fig-category-analysis-2.png" class="img-fluid figure-img" data-ref-parent="fig-category-analysis" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-category-analysis-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Distinctive Terms by Category
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-category-analysis-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10: Category-Specific Text Analysis
</figcaption>
</figure>
</div>
</section>
<section id="semantic-analysis" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="semantic-analysis"><span class="header-section-number">3.3</span> Semantic Analysis</h3>
<p>Topic Modeling</p>
<p>Latent Dirichlet Allocation (LDA) to identify underlying topics</p>
<p>Topic distribution visualization</p>
<p>Topic coherence across categories</p>
<p>Word Embeddings Exploration</p>
<p>t-SNE or UMAP visualization of word vectors Clustering of semantically similar terms</p>
<p>Analogy relationships between key terms</p>
</section>
</section>
<section id="sec-meth" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="sec-meth"><span class="header-section-number">4</span> Modeling approach</h2>
<p>In classification tasks with imbalanced class distributions, standard machine learning models often become biased toward the majority class, resulting in poor performance on minority classes. This imbalance can lead to misleading accuracy scores, as the model may learn to predict the dominant class at the expense of others. To address this, we use class weighting strategies such as class_weight=‘balanced’ in logistic regression. This approach adjusts the contribution of each class to the loss function by assigning higher weights (see <a href="#eq-balanced-weight" class="quarto-xref">Equation&nbsp;1</a>) to underrepresented classes and lower weights to overrepresented ones, thereby mitigating the imbalance. By penalizing misclassifications of minority classes more heavily, balanced class weighting encourages the model to learn a more equitable decision boundary, improving metrics like recall and F1-score for all classes. This is particularly important in multi-label classification, where each label may exhibit different levels of frequency and relevance.</p>
<p><span id="eq-balanced-weight"><span class="math display">\[
w_i = \frac{n_{\text{samples}}}{n_{\text{classes}} \times n_i}
\tag{1}\]</span></span></p>
<p>We therefore opt for a tri-fold modeling approach. First, the baseline models using ‘CountVectorizer’ for tokenizations are calculated, using Logistic Regression, Balanced Logistic Regression as explained above and a Random Forest Tree Classifier for subsequent classifications. We included a Random Forest model because of its strong performance and high computational efficiency for classification tasks in general. Second, the same models are employed using TF-IDF to tokenize documents. Thirdly, a pre-trained BERT model is fitted to the data. The exploratory data analysis in <a href="#sec-eda" class="quarto-xref">Section&nbsp;3</a> points in various bits, for example the analysis of word frequency according to Zipf’s law, the analysis of most common and distinctive terms as well as the contextual knowledge of UN reporting schemes, that this class of models fits well for the task.</p>
<section id="term-frequencyinverse-document-frequency-tf-idf" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="term-frequencyinverse-document-frequency-tf-idf"><span class="header-section-number">4.1</span> Term Frequency–Inverse Document Frequency (TF-IDF)</h3>
<p>As shown in <a href="#sec-eda" class="quarto-xref">Section&nbsp;3</a>, the formalized United nations language in reporting activities combined with the technical and relevant terms for each category lead to restrictions in using simple word count vectors. Replacing raw word counts with Term Frequency–Inverse Document Frequency (TF-IDF) representations can significantly enhance the effectiveness of machine learning models in text analysis, even when stopwords have already been removed. While count-based vectorization (as implemented in ‘CountVectorizer’ from ‘scikit-learn’) simply encodes the frequency of terms in each document, it treats all terms as equally informative. This approach can obscure the underlying semantic structure of the text, particularly when terms appear frequently across many documents but do not meaningfully contribute to document differentiation.</p>
<p>In contrast, TF-IDF weighting provides a more discriminative representation by scaling term frequencies by the inverse document frequency, thereby down-weighting terms that are common across the corpus and up-weighting those that are more unique to specific documents. This is especially useful in corpora where certain terms recur regularly but do not carry thematic significance. Although removing stopwords mitigates some of this issue, many domain-specific high-frequency terms (e.g., “government”, “peace”, “operation” in peacekeeping corpora) may still dominate the feature space in a count-based model without necessarily improving predictive performance. This is also shown in <a href="#fig-ngrams-1" class="quarto-xref">Figure&nbsp;4 (a)</a>, where many of the most frequent bigrams showed cross-cutting terminology like “human rights”, “reporting period”, “united nations”, “special representative” or “capacity building” (which is to some degree a term for a subgroup of peacekeeping activities, namely peacebuilding activities).</p>
<p>Moreover, TF-IDF has been shown to improve performance in a range of supervised learning tasks, particularly with linear classifiers such as logistic regression. By emphasizing the relative importance of terms, TF-IDF can enhance the signal-to-noise ratio in the input representation, leading to better generalization and interpretability. This is especially relevant when dealing with large vocabularies or class-imbalanced datasets like in our case, where raw frequency counts may skew model attention toward overly generic patterns.</p>
</section>
<section id="bidirectional-encoder-representations-from-transformers-bert" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="bidirectional-encoder-representations-from-transformers-bert"><span class="header-section-number">4.2</span> Bidirectional Encoder Representations from Transformers (BERT)</h3>
<p>Bidirectional Encoder Representations from Transformers (BERT) represents a paradigm shift in natural language processing by replacing surface-level feature engineering with deep contextual language understanding. Unlike traditional vectorization methods such as CountVectorizer used in the base models and TF-IDF, which generate fixed, sparse representations based on term-level statistics, BERT constructs dense, context-sensitive embeddings for each token, derived from its position within a sentence and the surrounding linguistic context. This approach allows BERT to model not only word meaning but also subtle syntactic and semantic relationships that are entirely invisible to TF-IDF and other bag-of-words representations.</p>
<p>The advantages of BERT are particularly salient in tasks that require understanding word sense disambiguation, idiomatic expressions, or syntactic dependencies — areas where frequency-based approaches struggle due to their inherent assumption of word independence. For example, TF-IDF treats the word “bank” identically in “river bank” and “investment bank,” whereas BERT dynamically adjusts the representation of “bank” depending on its context. This context-aware modeling enables BERT to capture nuanced meanings and improve downstream performance in classification, sentiment analysis and other text-based tasks.</p>
<p>Importantly, BERT eliminates the need for many traditional preprocessing steps such as stopword removal, stemming, or lemmatization. Because its transformer architecture learns language patterns directly from raw text, BERT can internally determine the informativeness of frequent function words and adjust their impact accordingly. This further distinguishes it from TF-IDF, which relies on external heuristics to mitigate the influence of high-frequency but low-information terms.</p>
<p>Moreover, BERT’s capacity to encode both local and long-range dependencies through self-attention mechanisms enhances its ability to generalize across domains and tasks, even with relatively limited annotated data. Fine-tuning BERT on a task-specific corpus allows the model to adapt to domain-specific language use while retaining its general-purpose linguistic knowledge, acquired during pretraining on large-scale corpora such as Wikipedia and BookCorpus.</p>
<p>Since the training of a BERT model is computationally expensive, …</p>
</section>
<section id="cross-validation-strategy" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="cross-validation-strategy"><span class="header-section-number">4.3</span> Cross-Validation strategy</h3>
<div id="tbl-class-distribution" class="quarto-float anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-class-distribution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3: Class distributions in training data.
</figcaption>
<div aria-describedby="tbl-class-distribution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<thead>
<tr class="header">
<th>Category</th>
<th>Count</th>
<th>Proportion</th>
<th>Percentage</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>PoliceReform</td>
<td>525</td>
<td>0.2886</td>
<td>28.86%</td>
</tr>
<tr class="even">
<td>Operations_PatrolsInterventions</td>
<td>151</td>
<td>0.0830</td>
<td>8.30%</td>
</tr>
<tr class="odd">
<td>StateAdministration</td>
<td>219</td>
<td>0.1204</td>
<td>12.04%</td>
</tr>
<tr class="even">
<td>RefugeeAssistance</td>
<td>103</td>
<td>0.0566</td>
<td>5.66%</td>
</tr>
<tr class="odd">
<td>ElectionAssistance</td>
<td>112</td>
<td>0.0616</td>
<td>6.16%</td>
</tr>
<tr class="even">
<td>LegalReform</td>
<td>129</td>
<td>0.0709</td>
<td>7.09%</td>
</tr>
<tr class="odd">
<td>CivilSocietyAssistance</td>
<td>161</td>
<td>0.0885</td>
<td>8.85%</td>
</tr>
<tr class="even">
<td><strong>Total</strong></td>
<td>1819</td>
<td>1.0000</td>
<td>100.00%</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>As can be seen in <a href="#tbl-class-distribution" class="quarto-xref">Table&nbsp;3</a>, the seven most coded categories selected for this feasibility test were still highly unbalanced. The imbalance ratio between the most frequent and least frequent was 5.1, compared to 5.31 for our target categories among the whole PACT 2.0 data set. The class distribution table for the full PACT 2.0 data set can be found in <a href="#tbl-class-distribution-full" class="quarto-xref">Table&nbsp;4</a> in the Annex.</p>
<p>To ensure robust model evaluation, we employed Stratified K-Fold Cross-Validation. Specifically, we used the ‘IterativeStratification’ function from the ‘skmultilearn’ library, which is tailored for multilabel classification. This strategy splits the data into <em>K</em> folds while preserving the label distribution across each fold, which is critical given the imbalanced and multi-label nature of the dataset. Unlike standard K-Fold, stratification helps prevent biased performance estimates that can occur if rare labels are unevenly distributed. By training and testing across multiple stratified splits, we obtain a more reliable estimate of model performance and ensure that each model is evaluated on diverse subsets of the data while still maintaining representative label proportions. This makes the approach well-suited for our multi-class, multi-label classification task.</p>
<p>The typical StratifiedKFold in ‘scikit-learn’ has a random state parameter to shuffle the data before splitting, which is useful to ensure reproducibility. However, ‘IterativeStratification’ from ‘skmultilearn.model_selection’ does not support a random state parameter, because it uses a deterministic algorithm to ensure that label distributions are balanced in each fold. Shuffling or adding randomness would disrupt the iterative label-balancing process, which is the entire point of using this strategy. Since the same cross-validation was used across all models, results are still comparable.</p>
</section>
</section>
<section id="sec-results" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="sec-results"><span class="header-section-number">5</span> Results</h2>
<section id="parameter-optimization" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="parameter-optimization"><span class="header-section-number">5.1</span> Parameter optimization</h3>
<p>All BoW models reported in the results section are parameter optimized using ‘GridSearchCV’.</p>
</section>
</section>
<section id="sec-conc" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="sec-conc"><span class="header-section-number">6</span> Conclusion</h2>
<p>Limitations: - geographic anchors - subset of missions</p>
<p>Combining word frequency tokenization with TF-IDF plus penalty term logistic regression for the balance between important key terms for detecting an activity and distinctive terms (TF-IDF scores) for fine-grained categorization for</p>
</section>
<section id="annex" class="level2 annex" data-number="7">
<h2 class="annex anchored" data-number="7" data-anchor-id="annex"><span class="header-section-number">7</span> Annex</h2>
<div id="tbl-class-distribution-full" class="quarto-float anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-class-distribution-full-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;4: Class distributions in full PACT 2.0 data.
</figcaption>
<div aria-describedby="tbl-class-distribution-full-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<thead>
<tr class="header">
<th>Category</th>
<th>Count</th>
<th>Proportion</th>
<th>Percentage</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>PoliceReform</td>
<td>1232</td>
<td>0.2532</td>
<td>25.32%</td>
</tr>
<tr class="even">
<td>Operations_PatrolsInterventions</td>
<td>587</td>
<td>0.1207</td>
<td>12.07%</td>
</tr>
<tr class="odd">
<td>StateAdministration</td>
<td>581</td>
<td>0.1194</td>
<td>11.94%</td>
</tr>
<tr class="even">
<td>HumanRights</td>
<td>450</td>
<td>0.0925</td>
<td>9.25%</td>
</tr>
<tr class="odd">
<td>JusticeSectorReform</td>
<td>435</td>
<td>0.0894</td>
<td>8.94%</td>
</tr>
<tr class="even">
<td>Demilitarization</td>
<td>350</td>
<td>0.0719</td>
<td>7.19%</td>
</tr>
<tr class="odd">
<td>RefugeeAssistance</td>
<td>312</td>
<td>0.0641</td>
<td>6.41%</td>
</tr>
<tr class="even">
<td>ElectionAssistance</td>
<td>265</td>
<td>0.0545</td>
<td>5.45%</td>
</tr>
<tr class="odd">
<td>BorderControl</td>
<td>251</td>
<td>0.0516</td>
<td>5.16%</td>
</tr>
<tr class="even">
<td>MilitaryReform</td>
<td>247</td>
<td>0.0508</td>
<td>5.08%</td>
</tr>
<tr class="odd">
<td>LegalReform</td>
<td>235</td>
<td>0.0483</td>
<td>4.83%</td>
</tr>
<tr class="even">
<td>CivilSocietyAssistance</td>
<td>232</td>
<td>0.0477</td>
<td>4.77%</td>
</tr>
<tr class="odd">
<td>PrisonReform</td>
<td>228</td>
<td>0.0469</td>
<td>4.69%</td>
</tr>
<tr class="even">
<td>HumanitarianRelief</td>
<td>222</td>
<td>0.0456</td>
<td>4.56%</td>
</tr>
<tr class="odd">
<td>Gender</td>
<td>209</td>
<td>0.0430</td>
<td>4.30%</td>
</tr>
<tr class="even">
<td>PartyAssistance</td>
<td>178</td>
<td>0.0366</td>
<td>3.66%</td>
</tr>
<tr class="odd">
<td>DemocraticInstitutions</td>
<td>144</td>
<td>0.0296</td>
<td>2.96%</td>
</tr>
<tr class="even">
<td>SexualViolence</td>
<td>142</td>
<td>0.0292</td>
<td>2.92%</td>
</tr>
<tr class="odd">
<td>ControlSALW</td>
<td>133</td>
<td>0.0273</td>
<td>2.73%</td>
</tr>
<tr class="even">
<td>Operations_UseOfForce</td>
<td>132</td>
<td>0.0271</td>
<td>2.71%</td>
</tr>
<tr class="odd">
<td>TransitionalJustice</td>
<td>123</td>
<td>0.0253</td>
<td>2.53%</td>
</tr>
<tr class="even">
<td>PublicHealth</td>
<td>109</td>
<td>0.0224</td>
<td>2.24%</td>
</tr>
<tr class="odd">
<td>LocalReconciliation</td>
<td>102</td>
<td>0.0210</td>
<td>2.10%</td>
</tr>
<tr class="even">
<td>ElectoralSecurity</td>
<td>99</td>
<td>0.0203</td>
<td>2.03%</td>
</tr>
<tr class="odd">
<td>EconomicDevelopment</td>
<td>98</td>
<td>0.0201</td>
<td>2.01%</td>
</tr>
<tr class="even">
<td>ChildRights</td>
<td>96</td>
<td>0.0197</td>
<td>1.97%</td>
</tr>
<tr class="odd">
<td>DisarmamentDemobilization</td>
<td>95</td>
<td>0.0195</td>
<td>1.95%</td>
</tr>
<tr class="even">
<td>Media</td>
<td>80</td>
<td>0.0164</td>
<td>1.64%</td>
</tr>
<tr class="odd">
<td>Demining</td>
<td>79</td>
<td>0.0162</td>
<td>1.62%</td>
</tr>
<tr class="even">
<td>National_Reconciliation</td>
<td>77</td>
<td>0.0158</td>
<td>1.58%</td>
</tr>
<tr class="odd">
<td>CivilianProtection</td>
<td>61</td>
<td>0.0125</td>
<td>1.25%</td>
</tr>
<tr class="even">
<td>Reintegration</td>
<td>54</td>
<td>0.0111</td>
<td>1.11%</td>
</tr>
<tr class="odd">
<td>Resources</td>
<td>38</td>
<td>0.0078</td>
<td>0.78%</td>
</tr>
<tr class="even">
<td>VoterEducation</td>
<td>30</td>
<td>0.0062</td>
<td>0.62%</td>
</tr>
<tr class="odd">
<td>StateAuthority</td>
<td>23</td>
<td>0.0047</td>
<td>0.47%</td>
</tr>
<tr class="even">
<td>PowerSharing</td>
<td>9</td>
<td>0.0018</td>
<td>0.18%</td>
</tr>
<tr class="odd">
<td>ArmsEmbargo</td>
<td>0</td>
<td>0.0000</td>
<td>0.00%</td>
</tr>
<tr class="even">
<td><strong>Total Documents</strong></td>
<td>4865</td>
<td>-</td>
<td>-</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<dl>
<dt>Title:</dt>
<dd>
<p>Brief description. (file type)</p>
</dd>
</dl>

</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Bachl2024" class="csl-entry" role="listitem">
Bachl, M., and Scharkow, M. (forthcoming), <span>“Computational text analysis,”</span> in <em>Handbook of quantitative research methods in communication science</em>, ed. L. Shen, De Gruyter Mouton.
</div>
<div id="ref-Bachl2017" class="csl-entry" role="listitem">
Bachl, M., and Scharkow, M. (2017), <span>“Correcting measurement error in content analysis,”</span> <em>Communication Methods and Measures</em>, Routledge, 11, 87–104. <a href="https://doi.org/10.1080/19312458.2017.1305103">https://doi.org/10.1080/19312458.2017.1305103</a>.
</div>
<div id="ref-Blair2022" class="csl-entry" role="listitem">
Blair, R. A., Di Salvatore, J., and Smidt, H. M. (2022), <span>“When do <span>UN</span> peacekeeping operations implement their mandates?”</span> <em>American Journal of Political Science</em>, 66, 664–680. <a href="https://doi.org/10.1111/ajps.12650">https://doi.org/10.1111/ajps.12650</a>.
</div>
<div id="ref-UN2019" class="csl-entry" role="listitem">
<em><a href="https://resourcehub01.blob.core.windows.net/%24web/Policy%20and%20Guidance/corepeacekeepingguidance/Mission%20Management%2C%20Planning%20and%20Oversight/Analysis%2C%20Reporting%20and%20Monitoring/2019.10%20Integrated%20Reporting%20from%20Peacekeeping%20Operations%20to%20UNHQ%20%28SOP%29.pdf">Integrated reporting from peacekeeping operations to UNHQ: Standard operating procedure</a></em> (2019), United Nations Department of Peace Operations.
</div>
<div id="ref-Krippendorff2018" class="csl-entry" role="listitem">
Krippendorff, K. (2018), <em>Content analysis: An introduction to its methodology</em>, Sage publications.
</div>
<div id="ref-PACT2" class="csl-entry" role="listitem">
Otto, S. (2024), <span>“<span>Peacekeeping Activity (PACT) Dataset 2.0</span>,”</span> Harvard Dataverse. <a href="https://doi.org/10.7910/DVN/TQ8ETA">https://doi.org/10.7910/DVN/TQ8ETA</a>.
</div>
<div id="ref-PACT2CB" class="csl-entry" role="listitem">
Otto, S., and Honda, M. (2024), <span>“Codebook for the <span>Peacekeeping Activity (PACT) Dataset 2.0</span>,”</span> <a href="https://dataverse.harvard.edu/file.xhtml?fileId=10266552&amp;version=2.0" class="uri">https://dataverse.harvard.edu/file.xhtml?fileId=10266552&amp;version=2.0</a>.
</div>
<div id="ref-Otto2024" class="csl-entry" role="listitem">
Otto, S., Kube, F., and Smidt, H. (2024), <span>“<span>UN</span> peacekeeping upon deployment: Peacekeeping activities in theory and practice,”</span> <em>Cooperation and Conflict</em>, 59, 488–509. <a href="https://doi.org/10.1177/00108367241235888">https://doi.org/10.1177/00108367241235888</a>.
</div>
<div id="ref-Salvatore2022" class="csl-entry" role="listitem">
Salvatore, J. D., Lundgren, M., Oksamytna, K., and Smidt, H. M. (2022), <span>“Introducing the <span>Peacekeeping Mandates (PEMA)</span> dataset,”</span> <em>Journal of Conflict Resolution</em>, 66, 924–951. <a href="https://doi.org/10.1177/00220027211068897">https://doi.org/10.1177/00220027211068897</a>.
</div>
<div id="ref-Zipf1949" class="csl-entry" role="listitem">
Zipf, G. K. (1949), <em>Human behavior and the principle of least effort: An introduction to human ecology</em>, Cambridge, MA: Addison-Wesley.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>The UNPKOs included are: MINUGUA, MINUJUSTH, MINUSTAH, MIPONUH, ONUCA, ONUSAL, UNCPSG, UNCRO, UNMIBH, UNMIH, UNMIK, UNMISET, UNMIT, UNMOP, UNMOT, UNOMIG, UNPREDEP, UNPROFOR, UNSMIH, UNTAC, UNTAES, UNTAET and UNTMIH.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>On a side note, this fine-grained data which would allow us to train our models beyond the scope here, is only available for 143 out of 470 total reports. Therefore, pre-trained BERT-class models were used.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Two more reports failed the parsing pipeline due to incompatible PDF formats and were therefore deleted from the pre-selection. While the reports were the standard page size of 612 x 792 units, the bounding box to extract the main text failed to adjust for these reports.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>While this could theoretically be the case, we only encountered edge cases with years (e.g.&nbsp;2003), which the regex was adjusted for by only selecting r”“.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>